{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"origin_pos":2,"tab":["pytorch"],"id":"MmKhTsHpiJWU","executionInfo":{"status":"ok","timestamp":1641514227012,"user_tz":0,"elapsed":221,"user":{"displayName":"田浩哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07265567740542229782"}}},"outputs":[],"source":["import torch\n","from torch import nn"]},{"cell_type":"markdown","source":["$$f(\\mathbf{q}, (\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)) = \\sum_{i=1}^m \\alpha(\\mathbf{q}, \\mathbf{k}_i) \\mathbf{v}_i \\in \\mathbb{R}^v,$$\n","\n","$$a(\\mathbf q, \\mathbf k) = \\mathbf w_v^\\top \\text{tanh}(\\mathbf W_q\\mathbf q + \\mathbf W_k \\mathbf k) \\in \\mathbb{R},$$"],"metadata":{"id":"7ROX9V3pyrUn"}},{"cell_type":"code","source":["batch_size = 2\n","query_size = 10\n","num_keys = 5\n","key_size = 2\n","value_size = 4\n","\n","queries = torch.normal(0,1,(batch_size,1,query_size)) # (batch-size * number of queries * each query has 10 features)\n","keys = torch.ones((batch_size,num_keys,key_size))         # (batch-size * number key value pairs * each key has 2 features)\n","val_instance = torch.arange(num_keys*value_size, dtype=torch.float32).reshape(1,num_keys,value_size)\n","values = val_instance.repeat(batch_size,1,1)    # (batch-size * number key value pairs * each value has 4 features)\n","print(\"q size: \", queries.shape)\n","print(\"k size: \", keys.shape)\n","print(\"v size: \", values.shape)"],"metadata":{"id":"dFqNehWClFil","executionInfo":{"status":"ok","timestamp":1641514227255,"user_tz":0,"elapsed":9,"user":{"displayName":"田浩哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07265567740542229782"}},"outputId":"3cfe8e32-5c69-45b7-f32f-43f6a5153c4c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["q size:  torch.Size([2, 1, 10])\n","k size:  torch.Size([2, 5, 2])\n","v size:  torch.Size([2, 5, 4])\n"]}]},{"cell_type":"code","source":["num_hiddens = 20\n","W_k = nn.Linear(key_size, num_hiddens, bias=False)\n","W_q = nn.Linear(query_size, num_hiddens, bias=False)\n","w_v = nn.Linear(num_hiddens, 1, bias=False)\n","Wq, Wk = W_q(queries), W_k(keys)\n","print(\"W_q*q size:\", Wq.shape)\n","print(\"* Note: (batch_size, num_queries, num_hidden)\")\n","print(\"W_k*k size:\", Wk.shape)\n","print(\"* Note: (batch_size, number of key value pairs, num_hidden)\")"],"metadata":{"id":"0qetrD3JwCXx","executionInfo":{"status":"ok","timestamp":1641514227462,"user_tz":0,"elapsed":213,"user":{"displayName":"田浩哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07265567740542229782"}},"outputId":"01b704d4-db00-490b-a2fa-f5715da9c897","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["W_q*q size: torch.Size([2, 1, 20])\n","* Note: (batch_size, num_queries, num_hidden)\n","W_k*k size: torch.Size([2, 5, 20])\n","* Note: (batch_size, number of key value pairs, num_hidden)\n"]}]},{"cell_type":"code","source":["features = Wq.unsqueeze(2) + Wk.unsqueeze(1)\n","features = torch.tanh(features)\n","print(\"W_q*q+W_k*k size: \",features.shape)\n","scores = w_v(features).squeeze(-1)\n","print(\"attention score size: \",scores.shape)"],"metadata":{"id":"8JAEkgIQ0Gww","executionInfo":{"status":"ok","timestamp":1641514227463,"user_tz":0,"elapsed":10,"user":{"displayName":"田浩哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07265567740542229782"}},"outputId":"60da51f0-da0d-4fee-88de-debe3ea66f03","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["W_q*q+W_k*k size:  torch.Size([2, 1, 5, 20])\n","attention score size:  torch.Size([2, 1, 5])\n"]}]},{"cell_type":"markdown","source":["Note value size = 4.\n","\n","$f(\\mathbf{q}) = \\alpha^{2\\times1\\times5} \\mathbf{v}_i^{5\\times4} \\in \\mathbb{R}^v,$"],"metadata":{"id":"7LJuaBZz1dPP"}},{"cell_type":"code","source":["attention_weights = torch.softmax(scores, dim=1)\n","f = torch.bmm(attention_weights, values)\n","print(\"f(q) size: \",f.shape)"],"metadata":{"id":"AsIq2A1G2e67","executionInfo":{"status":"ok","timestamp":1641514227466,"user_tz":0,"elapsed":9,"user":{"displayName":"田浩哲","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07265567740542229782"}},"outputId":"37372930-7d1a-4a1a-988f-39e6914e6035","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["f(q) size:  torch.Size([2, 1, 4])\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"AdditiveAttention.ipynb","provenance":[{"file_id":"https://github.com/d2l-ai/d2l-pytorch-colab/blob/master/chapter_attention-mechanisms/attention-scoring-functions.ipynb","timestamp":1641514149233}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}